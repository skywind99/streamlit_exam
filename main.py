# app.py
import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

st.set_page_config(page_title="ì›¹ íŒŒì„œ", layout="wide")

st.title("ğŸ” ì›¹ í˜ì´ì§€ íŒŒì„œ")

# ì‚¬ìš©ì ì…ë ¥
url = st.text_input("ğŸ”— íŒŒì‹±í•  ì‚¬ì´íŠ¸ URLì„ ì…ë ¥í•˜ì„¸ìš”:")
tag = st.text_input("ğŸ”– ê°€ì ¸ì˜¬ HTML íƒœê·¸ (ì˜ˆ: div, table, img ë“±):")
attr = st.text_input("ğŸ¯ íŠ¹ì • ì†ì„± (ì„ íƒ, ì˜ˆ: class=main ë˜ëŠ” id=content)")

if st.button("íŒŒì‹± ì‹œì‘"):
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        # íƒœê·¸ + ì†ì„± í•„í„°ë§
        if "=" in attr:
            key, val = attr.split("=")
            elements = soup.find_all(tag, {key: val})
        else:
            elements = soup.find_all(tag)

        st.success(f"ì´ {len(elements)}ê°œ ìš”ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        for i, el in enumerate(elements):
            st.markdown(f"---\n### â–¶ï¸ ìš”ì†Œ {i+1}")

            # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            if el.find("img"):
                for img in el.find_all("img"):
                    src = img.get("src")
                    if src:
                        full_url = urljoin(url, src)
                        st.image(full_url, caption=full_url)

            # ë§í¬ê°€ ìˆìœ¼ë©´ í‘œì‹œ
            if el.find("a"):
                for a in el.find_all("a"):
                    href = a.get("href")
                    if href:
                        full_url = urljoin(url, href)
                        st.markdown(f"[ë§í¬]({full_url})")

            # í…ìŠ¤íŠ¸ ì¶œë ¥
            text = el.get_text(strip=True)
            if text:
                st.text(text)

    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
