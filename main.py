import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import pandas as pd

st.set_page_config(page_title="ì›¹ íŒŒì„œ ê°œì„ íŒ", layout="wide")
st.title("ğŸ§© HTML íŒŒì„œ with í‘œ & ë§í¬ í…ìŠ¤íŠ¸ ê°œì„ ")

url = st.text_input("ğŸ”— ë¶„ì„í•  ì›¹í˜ì´ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”:")
tag_options = ['table', 'img', 'a', 'div', 'p']
tag = st.selectbox("ğŸ”– ë¶„ì„í•  HTML íƒœê·¸ ì„ íƒ", tag_options)

if url and tag and st.button("íŒŒì‹± ì‹œì‘"):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, "html.parser")
        elements = soup.find_all(tag)

        st.success(f"{len(elements)}ê°œì˜ `{tag}` íƒœê·¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        for idx, el in enumerate(elements):
            st.markdown(f"---\n### â–¶ï¸ {tag} ìš”ì†Œ {idx + 1}")

            # âœ… table ì²˜ë¦¬
            if tag == "table":
                rows = el.find_all("tr")
                data = []
                max_cols = 0

                for row in rows:
                    cols = row.find_all(["td", "th"])
                    row_data = []
                    for col in cols:
                        content = col.get_text(strip=True)
                        row_data.append(content)
                    max_cols = max(max_cols, len(row_data))
                    data.append(row_data)

                # ì—´ ê°œìˆ˜ê°€ ë‹¤ë¥¼ ê²½ìš° ë§ì¶°ì¤Œ
                for row in data:
                    while len(row) < max_cols:
                        row.append("")

                df = pd.DataFrame(data)
                st.table(df)

            # âœ… a íƒœê·¸ ê°œì„ 
            elif tag == "a":
                href = el.get("href")
                text = el.get_text(strip=True)

                if not text:
                    text = "(ë¹ˆ í…ìŠ¤íŠ¸ ë˜ëŠ” span ë‚´ë¶€ í…ìŠ¤íŠ¸ ì—†ìŒ)"

                st.markdown(f"ğŸ”— URL: `{urljoin(url, href)}`")
                st.markdown(f"ğŸ“ í…ìŠ¤íŠ¸: `{text}`")

            # âœ… ê¸°íƒ€ íƒœê·¸: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ + ë§í¬ ë¶„ì„
            else:
                text = el.get_text(strip=True)
                if text:
                    st.markdown(f"ğŸ“ í…ìŠ¤íŠ¸: `{text}`")

                imgs = el.find_all("img")
                for img in imgs:
                    src = urljoin(url, img.get("src", ""))
                    st.markdown(f"ğŸ–¼ï¸ ì´ë¯¸ì§€: `{src}`")

                links = el.find_all("a")
                for a in links:
                    href = urljoin(url, a.get("href", ""))
                    a_text = a.get_text(strip=True)
                    if not a_text:
                        a_text = "(ë§í¬ ì•ˆì— í…ìŠ¤íŠ¸ ì—†ìŒ)"
                    st.markdown(f"ğŸ”— ë§í¬: `{href}` / ğŸ“ í…ìŠ¤íŠ¸: `{a_text}`")

    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
